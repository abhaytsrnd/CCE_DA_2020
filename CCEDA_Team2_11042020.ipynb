{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanf (arg1): # Array of numbers to be passed\n",
    "    if len(arg1) == 0:\n",
    "        return(\"Array is empty\")\n",
    "    sumarg1 = 0\n",
    "    for number in range(len(arg1)):\n",
    "        sumarg1 += arg1[number]\n",
    "        Avg = sumarg1/len(arg1)\n",
    "    return(Avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varf (arg1): # Array of numbers to be passed\n",
    "    if len(arg1) == 0:\n",
    "        return(\"Array is empty\")\n",
    "    meanv = meanf(arg1)\n",
    "    sqdsumdiff = 0\n",
    "    for number in range(len(arg1)):\n",
    "        sqdsumdiff += (arg1[number]-meanv)*(arg1[number]-meanv)\n",
    "        var = sqdsumdiff/(len(arg1)-1)\n",
    "    return (meanv,var) \n",
    " # unpack this output tuple for extracting meanv and Var after storing this in any variable eg. z (Mean, Variance) = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a dataframe from original, where values are identified as invalid and a RC list created.\n",
    "\n",
    "def BldDefDF(arg1,arg2,arg3) : \n",
    "    # arg1 df; \n",
    "    # arg2 list of RCs  of original DF where data is identified as invalid or NaN\n",
    "    # arg3 is list of Col names\n",
    "\n",
    "\n",
    "    RLst = []                       # list containing 'R' values from list of RCs list\n",
    "    for pshin in range(len(arg2)) :\n",
    "        RLst.append(arg2[pshin][0])\n",
    "\n",
    "    Compact_list = []               # After Removing Duplicates from Rlist\n",
    "    for num in RLst:\n",
    "        if num not in Compact_list: \n",
    "            Compact_list.append(num) \n",
    "    Compact_list.sort()\n",
    "  \n",
    "    DFDef = pd.DataFrame(columns = arg3)\n",
    "    for itno in range(len(Compact_list)) :\n",
    "        DFDef = DFDef.append(arg1.iloc[Compact_list[itno]])\n",
    "\n",
    "    return(DFDef,Compact_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for getting row and columns details of each NAN\n",
    "\n",
    "def Nandet(arg1,arg2,arg3) :  # df1,ColNames1;LenCol1\n",
    "    \n",
    "    \n",
    "    TotNan = 0\n",
    "    TotRC = []\n",
    "    for ColNo in range(arg3) :\n",
    "        ColSel = arg2[ColNo]\n",
    "        NulRws  = (arg1[arg1[ColSel].isnull()].index.tolist())  #get Row nos for Nan in that Column\n",
    "        NRLen = len(NulRws)\n",
    "        for NoNul in range(NRLen) :\n",
    "            TotNan += 1\n",
    "            TotRC.append([NulRws[NoNul],ColNo])              #Create RC for the Nans in that Column\n",
    "    #print(totNan,totRC)\n",
    "    #input(\"enter\")\n",
    "    return(TotNan,TotRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for invalid entries(other than NaNs) in text and numeric columns \n",
    "\n",
    "def DataValid (arg1,arg2,arg3,arg4,arg5): # df,LenDf,ColNames,ColTypes,LenCol\n",
    "     \n",
    "    df1        = arg1   \n",
    "    LenDf1     = arg2\n",
    "    ColNames1  = arg3\n",
    "    ColTyp     = arg4\n",
    "    LenCol1    = arg5\n",
    "\n",
    "    Nopbl = \"True\"\n",
    "    DelRws = \"N\"\n",
    "    NaNRC = []\n",
    "    PrblRCs =[]\n",
    "    ColAvgVar =[[]]\n",
    "    \n",
    "    (TotNoNaN,TotRC) = Nandet(arg1,arg3,arg5)  # To get RC details of all NaNs.\n",
    "    \n",
    "    for noofcol in range(arg5) :\n",
    "        ColValidNos = []\n",
    "        NonStr = 0\n",
    "        NonNmr = 0  \n",
    "        NoofNaN = sum(pd.isnull(df1[ColNames1[noofcol]]))   # summing number of Nan in each column.\n",
    "        for noofrw in range(arg2) :            \n",
    "            if (ColTyp[noofcol] == \"Text\" and type(arg1.iloc[noofrw,noofcol]) != str ) :\n",
    "                NonStr += 1\n",
    "                TotRC.append([noofrw,noofcol])\n",
    "                \n",
    "            if ColTyp[noofcol] == \"Numbers\" :\n",
    "                if type(df1.iloc[noofrw,noofcol]) != str :\n",
    "                    ColValidNos.append(df1.iloc[noofrw,noofcol])\n",
    "                if type(df1.iloc[noofrw,noofcol]) == str :\n",
    "                    NonNmr += 1\n",
    "                    TotRC.append([noofrw,noofcol])\n",
    "                \n",
    "        if ColTyp[noofcol] == \"Numbers\" :\n",
    "            ColValidNos1 =[]\n",
    "            for noc in range(len(ColValidNos)):\n",
    "                if ~np.isnan(ColValidNos[noc]) :\n",
    "                    ColValidNos1.append(ColValidNos[noc])\n",
    "            ColAvgVar = varf(ColValidNos1)\n",
    "            \n",
    "        if (NonNmr != 0 or NonStr != 0 or NoofNaN != 0) :\n",
    "            Nopbl = \"False\"\n",
    "            print(\"Column \",ColNames[noofcol],\" should have only \",ColTyp[noofcol]+\" but also contains\")\n",
    "            if ColTyp[noofcol] == \"Text\" :\n",
    "                msg = (str(NonStr)+\" Number of Non Strings of which \"+str(NoofNaN)+\" are NaNs.\")            \n",
    "            if ColTyp[noofcol] == \"Numbers\" :\n",
    "                msg = (str(NonNmr)+\" Number of Non Numericals and \"+str(NoofNaN)+\" Number of NaNs.\\nMean, Variance and Std Deviation of Valid entries in this column are \"+\"%.3f\" %ColAvgVar[0]+\"  \"+\"%.3f\" %ColAvgVar[1]+\" \"+\"%.3f\" %math.sqrt(ColAvgVar[1]))\n",
    "\n",
    "            print(msg,'\\n')\n",
    "            \n",
    "    if Nopbl == \"False\" :\n",
    "        (DFDefect,Dellst) = BldDefDF(arg1,TotRC,arg3)  #Building a dataframe having where values are identified as invalid.\n",
    "        print(\"Total Number of NaNs are :\",TotNoNaN,'.  Also check for other wrong entries as mentioned above. \\n')\n",
    "        print(\"Following is the list of rows where data is not valid and has to be corrected.\\nNo of defective rows presented\",len(DFDefect),\"of \",LenDf1,\"which is \",\"%.2f\" %(len(DFDefect)*100/LenDf1),\"%.\\n\\n\")\n",
    "        print(DFDefect)\n",
    "        print(\"\\nOnly defective data presented above. Complete including defective data given below, which could guide in rectifying\\n\")\n",
    "        print(df1)\n",
    "        DelRws = input(\"\\n\\nPlease go throuh the above data. Enter y to delete rows with defective data and proceed to prepare MongoDB. \\nWARNING !!!!!  Above mentioned % of data will be deleted !!!!!\\n\\n\")    \n",
    "        \n",
    "    if DelRws.upper() == \"Y\" :\n",
    "        print(ColNames1)\n",
    "        print(ColTyp)\n",
    "        df1 = df1.drop(Dellst,axis = 0)\n",
    "        \n",
    "        # Deleting columns with text\n",
    "        DelTxt = \"N\"\n",
    "        DelTxt = input(\"Please confirm if text columns are to be deleted\")\n",
    "        if DelTxt.upper() == \"Y\" :\n",
    "            Rst = 0\n",
    "            for noofcol in range(len(ColTyp)) :\n",
    "                if ColTyp[noofcol] == 'Text' :\n",
    "                    df1 = df1.drop(df1.columns[noofcol-Rst], axis = 1)\n",
    "                    Rst += 1\n",
    "        Nopbl = \"True\"\n",
    "    else:\n",
    "        print(\"Decided not to delete rows with defective data\")\n",
    "        df1 = df[0:0]\n",
    "    return(Nopbl,df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15% rows checked for identifying type of data in columns. \n",
    "\n",
    "def IdenColTyp(arg1,arg2,arg3) : \n",
    "  \n",
    "    # arg1 is df\n",
    "    # arg2 is LenDf\n",
    "    # arg3 is LenCol\n",
    "    #15% of rows checked but what if length > 10000  \n",
    "    \n",
    "    if ((round(15/100)*arg2)%2) == 0 :          # To ensure odd number of rows selected for checking.\n",
    "        QntytoChk = (round(15/100)*arg2)+1\n",
    "    else :\n",
    "        QntytoChk = (round(15/100)*arg2)\n",
    "        \n",
    "    ColTyp = []\n",
    "    ColAvg = []\n",
    "    for NoofCol in range(arg3) :\n",
    "        NoofRwChkd = 0\n",
    "        NoofStr = 0\n",
    "        NoofNmr = 0\n",
    "        randomlist = random.sample(range(0, arg2), QntytoChk)\n",
    "        while NoofRwChkd < QntytoChk :\n",
    "            RwNo  = randomlist[NoofRwChkd]             \n",
    "            if type(arg1.iloc[RwNo,NoofCol]) == str :\n",
    "                NoofStr += 1\n",
    "            else : \n",
    "                NoofNmr += 1\n",
    "            NoofRwChkd += 1\n",
    "        if NoofStr > NoofNmr :\n",
    "            ColTyp.append(\"Text\")\n",
    "        else :\n",
    "            ColTyp.append(\"Numbers\")\n",
    "            \n",
    "    return(ColTyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for availability of file containing data to be analysed.\n",
    "\n",
    "def FilChk() :\n",
    "    print(\"\\n\\n File will be checked in dir\",os.getcwd())\n",
    "    Contin = \"Y\"\n",
    "    while Contin == \"Y\" :\n",
    "        nfile = input (\"\\n Enter File Name with extension:\")\n",
    "        Flnm = os.getcwd()+\"\\\\\"+nfile\n",
    "        if os.path.isfile(Flnm) :\n",
    "            print (\"File\",Flnm,\"is available \\n\")\n",
    "            Contin = \"N\"\n",
    "        else :\n",
    "            print (\"File\",Flnm,\"is not available\\n\")\n",
    "            Quit = input(\"Enter Q  to quit\").upper()\n",
    "            if Quit == \"Q\" :\n",
    "                sys.exit('Quit on user input.')\n",
    "    return(Flnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing working directory\n",
    "\n",
    "def ChngDir() :\n",
    "    print(\"Current Working Directory \" , os.getcwd())\n",
    "    Contin = \"Y\"    \n",
    "    while Contin == \"Y\" :\n",
    "        nwdir = input (\"Enter Directory :\")\n",
    "        if os.path.exists(nwdir) :\n",
    "            os.chdir(nwdir)\n",
    "            print(\"Directory changed to \",os.getcwd())\n",
    "            nopbl = \"No\"\n",
    "            Contin = \"N\"\n",
    "        else:\n",
    "            print(\" Working Directory \",nwdir,\"  does not exist.\")\n",
    "            Quit = input(\"Enter Q  to quit\").upper()\n",
    "            if Quit == \"Q\" :\n",
    "                sys.exit('Quit on user input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory  C:\\Users\\Manjunatha-Think\n",
      "Enter Directory :C:\\Users\\Manjunatha-Think\n",
      "Directory changed to  C:\\Users\\Manjunatha-Think\n",
      "\n",
      "\n",
      " File will be checked in dir C:\\Users\\Manjunatha-Think\n",
      "\n",
      " Enter File Name with extension:Automobiles_price_mileage_country.csv\n",
      "File C:\\Users\\Manjunatha-Think\\Automobiles_price_mileage_country.csv is available \n",
      "\n",
      "\n",
      "The  columns in database are  :  ['Make', 'Country', 'Mileage', 'Price']\n",
      "The corresponding types are   :  ['Text', 'Text', 'Numbers', 'Numbers']\n",
      "Total no of rows are          :  45. \n",
      "\n",
      "Column  Make  should have only  Text but also contains\n",
      "5 Number of Non Strings of which 5 are NaNs. \n",
      "\n",
      "Column  Mileage  should have only  Numbers but also contains\n",
      "0 Number of Non Numericals and 6 Number of NaNs.\n",
      "Mean, Variance and Std Deviation of Valid entries in this column are 23.538  24.097 4.909 \n",
      "\n",
      "Column  Price  should have only  Numbers but also contains\n",
      "0 Number of Non Numericals and 2 Number of NaNs.\n",
      "Mean, Variance and Std Deviation of Valid entries in this column are 13454.744  14469342.576 3803.859 \n",
      "\n",
      "Total Number of NaNs are : 13 .  Also check for other wrong entries as mentioned above. \n",
      "\n",
      "Following is the list of rows where data is not valid and has to be corrected.\n",
      "No of defective rows presented 13 of  45 which is  28.89 %.\n",
      "\n",
      "\n",
      "                      Make Country  Mileage    Price\n",
      "0     Chevrolet Caprice V8     USA      NaN  14525.0\n",
      "26                     NaN   Japan     23.0  21498.0\n",
      "27                     NaN     USA     23.0  16145.0\n",
      "28                     NaN   Japan     24.0  13249.0\n",
      "29                     NaN     USA     24.0   9483.0\n",
      "30                     NaN   Japan     25.0   9599.0\n",
      "32     Mitsubishi Galant 4   Japan      NaN  10989.0\n",
      "33          Plymouth Laser     USA      NaN  10855.0\n",
      "34     Chevrolet Beretta 4     USA      NaN  10320.0\n",
      "35           Dodge Daytona     USA      NaN   9745.0\n",
      "36  Honda Prelude Si 4WS 4   Japan      NaN  13945.0\n",
      "43          Subaru Justy 3   Japan     34.0      NaN\n",
      "44         Toyota Tercel 4   Japan     35.0      NaN\n",
      "\n",
      "Only defective data presented above. Complete including defective data given below, which could guide in rectifying\n",
      "\n",
      "                             Make Country  Mileage    Price\n",
      "0            Chevrolet Caprice V8     USA      NaN  14525.0\n",
      "1         Chevrolet Lumina APV V6     USA     18.0  13995.0\n",
      "2          Dodge Grand Caravan V6     USA     18.0  15395.0\n",
      "3                Ford Aerostar V6     USA     18.0  12267.0\n",
      "4                 Ford Mustang V8     USA     19.0  12164.0\n",
      "5                    Mazda MPV V6   Japan     19.0  14944.0\n",
      "6                    Nissan Van 4   Japan     19.0  14799.0\n",
      "7             Chevrolet Camaro V8     USA     20.0  11545.0\n",
      "8                 Acura Legend V6   Japan     20.0  24760.0\n",
      "9      Ford LTD Crown Victoria V8     USA     20.0  17257.0\n",
      "10             Mitsubishi Wagon 4   Japan     20.0  14929.0\n",
      "11                Nissan Axxess 4   Japan     20.0  13949.0\n",
      "12            Mitsubishi Sigma V6   Japan     21.0  17879.0\n",
      "13               Nissan Santaza 4   Japan     21.0  11650.0\n",
      "14                Buick Century 4     USA     21.0  13150.0\n",
      "15                   Mazda 929 V6   Japan     21.0  23300.0\n",
      "16     Oldsmobile Cutlass Ciera 4     USA     21.0  13150.0\n",
      "17  Oldsmobile Cutlass Supreme V6     USA     21.0  14495.0\n",
      "18        Chrysler Le Baron Coupe     USA     22.0  12495.0\n",
      "19         Chrysler New Yorker V6     USA     22.0  16342.0\n",
      "20               Eagle Premier V6     USA     22.0  15350.0\n",
      "21                 Ford Taurus V6     USA     22.0  13195.0\n",
      "22               Nissan Maxima V6   Japan     22.0  17899.0\n",
      "23                Buick Skylark 4     USA     23.0  10565.0\n",
      "24            Oldsmobile Calais 4     USA     23.0   9955.0\n",
      "25            Ford Thunderbird V6     USA     23.0  14980.0\n",
      "26                            NaN   Japan     23.0  21498.0\n",
      "27                            NaN     USA     23.0  16145.0\n",
      "28                            NaN   Japan     24.0  13249.0\n",
      "29                            NaN     USA     24.0   9483.0\n",
      "30                            NaN   Japan     25.0   9599.0\n",
      "31           Chrysler Le Baron V6     USA     25.0  10945.0\n",
      "32            Mitsubishi Galant 4   Japan      NaN  10989.0\n",
      "33                 Plymouth Laser     USA      NaN  10855.0\n",
      "34            Chevrolet Beretta 4     USA      NaN  10320.0\n",
      "35                  Dodge Daytona     USA      NaN   9745.0\n",
      "36         Honda Prelude Si 4WS 4   Japan      NaN  13945.0\n",
      "37                    Subaru XT 4   Japan     28.0  13071.0\n",
      "38                     Ford Probe     USA     30.0  11470.0\n",
      "39                Mazda Prot_g_ 4   Japan     32.0   6599.0\n",
      "40                 Eagle Summit 4     USA     33.0   8895.0\n",
      "41                  Ford Escort 4     USA     33.0   7402.0\n",
      "42           Honda Civic CRX Si 4   Japan     33.0   9410.0\n",
      "43                 Subaru Justy 3   Japan     34.0      NaN\n",
      "44                Toyota Tercel 4   Japan     35.0      NaN\n",
      "\n",
      "\n",
      "Please go throuh the above data. Enter y to delete rows with defective data and proceed to prepare MongoDB. \n",
      "WARNING !!!!!  Above mentioned % of data will be deleted !!!!!\n",
      "\n",
      "y\n",
      "['Make', 'Country', 'Mileage', 'Price']\n",
      "['Text', 'Text', 'Numbers', 'Numbers']\n",
      "Please confirm if text columns are to be deletedy\n",
      "    Mileage    Price\n",
      "1      18.0  13995.0\n",
      "2      18.0  15395.0\n",
      "3      18.0  12267.0\n",
      "4      19.0  12164.0\n",
      "5      19.0  14944.0\n",
      "6      19.0  14799.0\n",
      "7      20.0  11545.0\n",
      "8      20.0  24760.0\n",
      "9      20.0  17257.0\n",
      "10     20.0  14929.0\n",
      "11     20.0  13949.0\n",
      "12     21.0  17879.0\n",
      "13     21.0  11650.0\n",
      "14     21.0  13150.0\n",
      "15     21.0  23300.0\n",
      "16     21.0  13150.0\n",
      "17     21.0  14495.0\n",
      "18     22.0  12495.0\n",
      "19     22.0  16342.0\n",
      "20     22.0  15350.0\n",
      "21     22.0  13195.0\n",
      "22     22.0  17899.0\n",
      "23     23.0  10565.0\n",
      "24     23.0   9955.0\n",
      "25     23.0  14980.0\n",
      "31     25.0  10945.0\n",
      "37     28.0  13071.0\n",
      "38     30.0  11470.0\n",
      "39     32.0   6599.0\n",
      "40     33.0   8895.0\n",
      "41     33.0   7402.0\n",
      "42     33.0   9410.0\n",
      "\n",
      "\n",
      "Do you want to create MongoDb of above Data Frame  \n",
      "\n",
      "Enter y/ny\n",
      "['Mileage', 'Price']\n",
      "2\n",
      "{'_id': 1, 'Mileage': 18.0, 'Price': 13995.0}\n",
      "{'_id': 2, 'Mileage': 18.0, 'Price': 15395.0}\n",
      "{'_id': 3, 'Mileage': 18.0, 'Price': 12267.0}\n",
      "{'_id': 4, 'Mileage': 19.0, 'Price': 12164.0}\n",
      "{'_id': 5, 'Mileage': 19.0, 'Price': 14944.0}\n",
      "{'_id': 6, 'Mileage': 19.0, 'Price': 14799.0}\n",
      "{'_id': 7, 'Mileage': 20.0, 'Price': 11545.0}\n",
      "{'_id': 8, 'Mileage': 20.0, 'Price': 24760.0}\n",
      "{'_id': 9, 'Mileage': 20.0, 'Price': 17257.0}\n",
      "{'_id': 10, 'Mileage': 20.0, 'Price': 14929.0}\n",
      "{'_id': 11, 'Mileage': 20.0, 'Price': 13949.0}\n",
      "{'_id': 12, 'Mileage': 21.0, 'Price': 17879.0}\n",
      "{'_id': 13, 'Mileage': 21.0, 'Price': 11650.0}\n",
      "{'_id': 14, 'Mileage': 21.0, 'Price': 13150.0}\n",
      "{'_id': 15, 'Mileage': 21.0, 'Price': 23300.0}\n",
      "{'_id': 16, 'Mileage': 21.0, 'Price': 13150.0}\n",
      "{'_id': 17, 'Mileage': 21.0, 'Price': 14495.0}\n",
      "{'_id': 18, 'Mileage': 22.0, 'Price': 12495.0}\n",
      "{'_id': 19, 'Mileage': 22.0, 'Price': 16342.0}\n",
      "{'_id': 20, 'Mileage': 22.0, 'Price': 15350.0}\n",
      "{'_id': 21, 'Mileage': 22.0, 'Price': 13195.0}\n",
      "{'_id': 22, 'Mileage': 22.0, 'Price': 17899.0}\n",
      "{'_id': 23, 'Mileage': 23.0, 'Price': 10565.0}\n",
      "{'_id': 24, 'Mileage': 23.0, 'Price': 9955.0}\n",
      "{'_id': 25, 'Mileage': 23.0, 'Price': 14980.0}\n",
      "{'_id': 26, 'Mileage': 25.0, 'Price': 10945.0}\n",
      "{'_id': 27, 'Mileage': 28.0, 'Price': 13071.0}\n",
      "{'_id': 28, 'Mileage': 30.0, 'Price': 11470.0}\n",
      "{'_id': 29, 'Mileage': 32.0, 'Price': 6599.0}\n",
      "{'_id': 30, 'Mileage': 33.0, 'Price': 8895.0}\n",
      "{'_id': 31, 'Mileage': 33.0, 'Price': 7402.0}\n",
      "{'_id': 32, 'Mileage': 33.0, 'Price': 9410.0}\n",
      "\n",
      "\n",
      "\n",
      "Data module completed\n"
     ]
    }
   ],
   "source": [
    "#source to mongod\n",
    "\n",
    "#%whos \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "\n",
    "ChngDir()                          #To change to directory containing working file\n",
    "\n",
    "TargetFile = FilChk()              # To get file name from user\n",
    "\n",
    "if TargetFile[-3:].upper() == \"CSV\":\n",
    "    df =pd.read_csv(TargetFile)\n",
    "    \n",
    "elif TargetFile[-3:].upper() == \"TXT\" :\n",
    "    df = pd.read_csv(TargetFile,delimiter=',')                        # HOW TO TAKE CARE OF OTHER DELIMITERS.\n",
    "\n",
    "elif TargetFile[-3:].upper() == \"XLS\" or TargetFile[-4:].upper() == \"XLSX\"  :\n",
    "    ShtName = input (\"\\n Enter Sheet name. If blank first sheet will taken:\")\n",
    "    if len(ShtName) == 0 :\n",
    "        df = pd.read_excel(TargetFile)\n",
    "    else :\n",
    "        df = pd.read_excel(TargetFile,sheet_name = ShtName)\n",
    "else :\n",
    "    input(\"not a suitable file\")\n",
    "    # exit()                                                            # how to break out.\n",
    "\n",
    "\n",
    "LenDf = len(df)\n",
    "\n",
    "ColNames  = []\n",
    "for Col in df.columns: \n",
    "    ColNames.append(Col)\n",
    "LenCol = len(ColNames)\n",
    "\n",
    "ColTypes = IdenColTyp(df,LenDf,LenCol)  # for finding out type of data column wise.\n",
    "\n",
    "print(\"\\nThe  columns in database are  : \", ColNames)     \n",
    "print(\"The corresponding types are   : \", ColTypes)\n",
    "print(\"Total no of rows are          :  \"+str(LenDf)+\". \\n\")\n",
    "\n",
    "(proceed,FinDf) = DataValid(df,LenDf,ColNames,ColTypes,LenCol)      #  function for validating data\n",
    "\n",
    "#FinDf.reset_index(inplace = True) # Check how to sort. if done this way,  extra index added #and data shifts \n",
    "# to right by one column and resulting MongoDb is wrong.\n",
    "\n",
    "if proceed == \"True\" :  \n",
    "    print(FinDf)\n",
    "    MongoDbreq = \"N\"\n",
    "    print(\"\\n\\nDo you want to create MongoDb of above Data Frame  \")\n",
    "    MongoDbreq = input (\"\\nEnter y/n\")\n",
    "    \n",
    "    if MongoDbreq.upper() == \"Y\" :\n",
    "    \n",
    "        myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "\n",
    "        LinRegDB = myclient[\"LinReg\"]            # DB for a group\n",
    "        LinRegIp = LinRegDB[\"LinReginput\"]       # Collection 1 input file\n",
    "        LinREgOp = LinRegDB[\"LinRegoutput\"]      # Collection 2 Results. (single or multiple for different groups)\n",
    "\n",
    "        delinp  = LinRegIp.delete_many({})       #  to ensure collectible is empty\n",
    "        delout =  LinREgOp.delete_many({})       #  to ensure collectible is empty\n",
    "\n",
    "        ColNames  = []\n",
    "        for Col in FinDf.columns: \n",
    "            ColNames.append(Col)\n",
    "        LenCol = len(ColNames)\n",
    "        print(ColNames)\n",
    "        print(LenCol)\n",
    "        LenFinDf = len(FinDf)\n",
    "        for noofrw in range(LenFinDf) :\n",
    "            rw = '{\"_id\" : ' + str(noofrw+1)\n",
    "            for noofcol in range(LenCol) :\n",
    "                rw = rw+', \"'+ColNames[noofcol]+'\": '\n",
    "\n",
    "                if type(FinDf.iloc[noofrw,noofcol]) == str :\n",
    "                    rw = rw+'\"'+(FinDf.iloc[noofrw,noofcol])+'\"'    #  to put quotes if data is a string\n",
    "                else :                                        \n",
    "                    rw = rw+str(FinDf.iloc[noofrw,noofcol])         # not putting quotes if not a string\n",
    "            rw = rw+' }'\n",
    "            rwdict = json.loads(rw)\n",
    "            x = LinRegIp.insert_one(rwdict)\n",
    "\n",
    "\n",
    "\n",
    "        for x in LinRegIp.find():\n",
    "            print(x)\n",
    "    else :\n",
    "        print(\"\\nMongodB not created\")\n",
    "        print(\"\\nFollowing Data frames available\")\n",
    "        %whos DataFrame\n",
    "        print(\"\\n\\nFinDf is the cleaned data base\")\n",
    "else :\n",
    "    print(\"\\n\\nData not cleaned so blank FinDF.\")\n",
    "        \n",
    "print(\"\\n\\n\\nData module completed\")\n",
    "    \n",
    "#del TargetFile, inject, Col ,rw           # strings\n",
    "#del rwdict,x                              # dict\n",
    "#del ColNames, ColTypes                    # lists\n",
    "#del LenCol, LenDf, noofcol, noofrw        # int\n",
    "#del proceed                               # bool\n",
    "# del BldDefDF, ChngDir, DataValid, FilChk, IdenColTyp, Modify_df, Nandet, meanf, varf  # funct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deltxtcol.csv Automobiles_price_mileage_country.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14944.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11545.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14929.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>21.0</td>\n",
       "      <td>17879.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>22.0</td>\n",
       "      <td>17899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13071.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8895.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9410.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mileage    Price\n",
       "1      18.0  13995.0\n",
       "2      18.0  15395.0\n",
       "3      18.0  12267.0\n",
       "4      19.0  12164.0\n",
       "5      19.0  14944.0\n",
       "6      19.0  14799.0\n",
       "7      20.0  11545.0\n",
       "8      20.0  24760.0\n",
       "9      20.0  17257.0\n",
       "10     20.0  14929.0\n",
       "11     20.0  13949.0\n",
       "12     21.0  17879.0\n",
       "13     21.0  11650.0\n",
       "14     21.0  13150.0\n",
       "15     21.0  23300.0\n",
       "16     21.0  13150.0\n",
       "17     21.0  14495.0\n",
       "18     22.0  12495.0\n",
       "19     22.0  16342.0\n",
       "20     22.0  15350.0\n",
       "21     22.0  13195.0\n",
       "22     22.0  17899.0\n",
       "23     23.0  10565.0\n",
       "24     23.0   9955.0\n",
       "25     23.0  14980.0\n",
       "31     25.0  10945.0\n",
       "37     28.0  13071.0\n",
       "38     30.0  11470.0\n",
       "39     32.0   6599.0\n",
       "40     33.0   8895.0\n",
       "41     33.0   7402.0\n",
       "42     33.0   9410.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
