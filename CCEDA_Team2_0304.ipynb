{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanf (arg1): # Array of numbers to be passed\n",
    "    if len(arg1) == 0:\n",
    "        return(\"Array is empty\")\n",
    "    sumarg1 = 0\n",
    "    for number in range(len(arg1)):\n",
    "        sumarg1 += arg1[number]\n",
    "        Avg = sumarg1/len(arg1)\n",
    "    return(Avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varf (arg1): # Array of numbers to be passed\n",
    "    if len(arg1) == 0:\n",
    "        return(\"Array is empty\")\n",
    "    meanv = meanf(arg1)\n",
    "    sqdsumdiff = 0\n",
    "    for number in range(len(arg1)):\n",
    "        sqdsumdiff += (arg1[number]-meanv)*(arg1[number]-meanv)\n",
    "        var = sqdsumdiff/(len(arg1)-1)\n",
    "    return (meanv,var) \n",
    " # unpack this output tuple for extracting meanv and Var after storing this in any variable eg. z (Mean, Variance) = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a dataframe from original, where values are identified as invalid and a RC list created.\n",
    "\n",
    "def BldDefDF(arg1,arg2,arg3) : \n",
    "    # arg1 df; \n",
    "    # arg2 list of RCs  of original DF where data is identified as invalid or NaN\n",
    "    # arg3 is list of Col names\n",
    "\n",
    "\n",
    "    RLst = []                       # list containing 'R' values from list of RCs list\n",
    "    for pshin in range(len(arg2)) :\n",
    "        RLst.append(arg2[pshin][0])\n",
    "\n",
    "    Compact_list = []               # After Removing Duplicates from Rlist\n",
    "    for num in RLst:\n",
    "        if num not in Compact_list: \n",
    "            Compact_list.append(num) \n",
    "    Compact_list.sort()\n",
    "  \n",
    "    DFDef = pd.DataFrame(columns = arg3)\n",
    "    for itno in range(len(Compact_list)) :\n",
    "        DFDef = DFDef.append(arg1.iloc[Compact_list[itno]])\n",
    "\n",
    "    return(DFDef,Compact_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for getting row and columns details of each NAN\n",
    "\n",
    "def Nandet(arg1,arg2,arg3) :  # df1,ColNames1;LenCol1\n",
    "    \n",
    "    \n",
    "    TotNan = 0\n",
    "    TotRC = []\n",
    "    for ColNo in range(arg3) :\n",
    "        ColSel = arg2[ColNo]\n",
    "        NulRws  = (arg1[arg1[ColSel].isnull()].index.tolist())  #get Row nos for Nan in that Column\n",
    "        NRLen = len(NulRws)\n",
    "        for NoNul in range(NRLen) :\n",
    "            TotNan += 1\n",
    "            TotRC.append([NulRws[NoNul],ColNo])              #Create RC for the Nans in that Column\n",
    "    #print(totNan,totRC)\n",
    "    #input(\"enter\")\n",
    "    return(TotNan,TotRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for invalid entries(other than NaNs) in text and numeric columns \n",
    "\n",
    "def DataValid (arg1,arg2,arg3,arg4,arg5): # df,LenDf,ColNames,ColTypes,LenCol\n",
    "     \n",
    "    df1        = arg1   \n",
    "    LenDf1     = arg2\n",
    "    ColNames1  = arg3\n",
    "    ColTyp     = arg4\n",
    "    LenCol1    = arg5\n",
    "\n",
    "    Nopbl = \"True\"\n",
    "    DelRws = \"N\"\n",
    "    NaNRC = []\n",
    "    PrblRCs =[]\n",
    "    ColAvgVar =[[]]\n",
    "    \n",
    "    (TotNoNaN,TotRC) = Nandet(arg1,arg3,arg5)  # To get RC details of all NaNs.\n",
    "    \n",
    "    for noofcol in range(arg5) :\n",
    "        ColValidNos = []\n",
    "        NonStr = 0\n",
    "        NonNmr = 0  \n",
    "        NoofNaN = sum(pd.isnull(df1[ColNames1[noofcol]]))   # summing number of Nan in each column.\n",
    "        for noofrw in range(arg2) :            \n",
    "            if (ColTyp[noofcol] == \"Text\" and type(arg1.iloc[noofrw,noofcol]) != str ) :\n",
    "                NonStr += 1\n",
    "                TotRC.append([noofrw,noofcol])\n",
    "                \n",
    "            if ColTyp[noofcol] == \"Numbers\" :\n",
    "                if type(df1.iloc[noofrw,noofcol]) != str :\n",
    "                    ColValidNos.append(df1.iloc[noofrw,noofcol])\n",
    "                if type(df1.iloc[noofrw,noofcol]) == str :\n",
    "                    NonNmr += 1\n",
    "                    TotRC.append([noofrw,noofcol])\n",
    "                \n",
    "        if ColTyp[noofcol] == \"Numbers\" :\n",
    "            ColValidNos1 =[]\n",
    "            for noc in range(len(ColValidNos)):\n",
    "                if ~np.isnan(ColValidNos[noc]) :\n",
    "                    ColValidNos1.append(ColValidNos[noc])\n",
    "            ColAvgVar = varf(ColValidNos1)\n",
    "            \n",
    "        if (NonNmr != 0 or NonStr != 0 or NoofNaN != 0) :\n",
    "            Nopbl = \"False\"\n",
    "            print(\"Column \",ColNames[noofcol],\" should have only \",ColTyp[noofcol]+\" but also contains\")\n",
    "            if ColTyp[noofcol] == \"Text\" :\n",
    "                msg = (str(NonStr)+\" Number of Non Strings of which \"+str(NoofNaN)+\" are NaNs.\")            \n",
    "            if ColTyp[noofcol] == \"Numbers\" :\n",
    "                msg = (str(NonNmr)+\" Number of Non Numericals and \"+str(NoofNaN)+\" Number of NaNs.\\nMean, Variance and Std Deviation of Valid entries in this column are \"+\"%.3f\" %ColAvgVar[0]+\"  \"+\"%.3f\" %ColAvgVar[1]+\" \"+\"%.3f\" %math.sqrt(ColAvgVar[1]))\n",
    "\n",
    "            print(msg,'\\n')\n",
    "            \n",
    "    if Nopbl == \"False\" :\n",
    "        (DFDefect,Dellst) = BldDefDF(arg1,TotRC,arg3)  #Building a dataframe having where values are identified as invalid.\n",
    "        print(\"Total Number of NaNs are :\",TotNoNaN,'.  Also check for other wrong entries as mentioned above. \\n')\n",
    "        print(\"Following is the list of rows where data is not valid and has to be corrected.\\nNo of defective rows presented\",len(DFDefect),\"of \",LenDf1,\"which is \",\"%.2f\" %(len(DFDefect)*100/LenDf1),\"%.\\n\\n\")\n",
    "        print(DFDefect)\n",
    "        print(\"\\nOnly defective data presented above. Complete including defective data given below, which could guide in rectifying\\n\")\n",
    "        print(df1)\n",
    "        DelRws = input(\"Please go throuh the above data. Enter y to delete rows with defective data and proceed to prepare MongoDB. \\nWARNING !!!!!  Above mentioned % of data will be deleted !!!!!\\n\")    \n",
    "        \n",
    "    if DelRws.upper() == \"Y\" :\n",
    "        df1 = df1.drop(Dellst,axis = 0)\n",
    "        Nopbl = \"True\"\n",
    "        \n",
    "    return(Nopbl,df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Injecting invalid data for testing\n",
    "\n",
    "def Modify_df(arg1,arg2,arg3) : # arg1 is df, arg2 is no of rows in df and arg3 is no of columns in df\n",
    "\n",
    "    for NoofCol in range(arg3) :\n",
    "        randomlist  = random.sample(range(0, arg2), 3)\n",
    "        randomlist2 = random.sample(range(0, arg2), 8)\n",
    "        i = 0\n",
    "        while i < 3 :\n",
    "            arg1.iloc[randomlist[i],NoofCol] = np.nan\n",
    "            i = i+1\n",
    "            \n",
    "    #for NoofRow in range(arg2) :       #entire column with nans.\n",
    "    #    arg1.iloc[NoofRow,1] = np.nan\n",
    "        \n",
    "        \n",
    "    j = 0\n",
    "    while j < 8:\n",
    "        arg1.iloc[randomlist2[j],0] = 1\n",
    "        arg1.iloc[randomlist2[j+1],2] = \"a\"\n",
    "        arg1.iloc[randomlist2[j+2],1] = 1\n",
    "        arg1.iloc[randomlist2[j+3],3] = \"a\"\n",
    "        j = j+4\n",
    "        \n",
    "    return(arg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15% rows checked for identifying type of data in columns. \n",
    "\n",
    "def IdenColTyp(arg1,arg2,arg3) : \n",
    "  \n",
    "    # arg1 is df\n",
    "    # arg2 is LenDf\n",
    "    # arg3 is LenCol\n",
    "    #15% of rows checked but what if length > 10000  \n",
    "    \n",
    "    if ((round(15/100)*arg2)%2) == 0 :          # To ensure odd number of rows selected for checking.\n",
    "        QntytoChk = (round(15/100)*arg2)+1\n",
    "    else :\n",
    "        QntytoChk = (round(15/100)*arg2)\n",
    "        \n",
    "    ColTyp = []\n",
    "    ColAvg = []\n",
    "    for NoofCol in range(arg3) :\n",
    "        NoofRwChkd = 0\n",
    "        NoofStr = 0\n",
    "        NoofNmr = 0\n",
    "        randomlist = random.sample(range(0, arg2), QntytoChk)\n",
    "        while NoofRwChkd < QntytoChk :\n",
    "            RwNo  = randomlist[NoofRwChkd]             \n",
    "            if type(arg1.iloc[RwNo,NoofCol]) == str :\n",
    "                NoofStr += 1\n",
    "            else : \n",
    "                NoofNmr += 1\n",
    "            NoofRwChkd += 1\n",
    "        if NoofStr > NoofNmr :\n",
    "            ColTyp.append(\"Text\")\n",
    "        else :\n",
    "            ColTyp.append(\"Numbers\")\n",
    "            \n",
    "    return(ColTyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for availability of file containing data to be analysed.\n",
    "\n",
    "def FilChk() :\n",
    "    print(\"\\n\\n File will be checked in dir\",os.getcwd())\n",
    "    Contin = \"Y\"\n",
    "    while Contin == \"Y\" :\n",
    "        nfile = input (\"\\n Enter File Name with extension:\")\n",
    "        Flnm = os.getcwd()+\"\\\\\"+nfile\n",
    "        if os.path.isfile(Flnm) :\n",
    "            print (\"File\",Flnm,\"is available \\n\")\n",
    "            Contin = \"N\"\n",
    "        else :\n",
    "            print (\"File\",Flnm,\"is not available\\n\")\n",
    "            Quit = input(\"Enter Q  to quit\").upper()\n",
    "            if Quit == \"Q\" :\n",
    "                sys.exit('Quit on user input.')\n",
    "    return(Flnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing working directory\n",
    "\n",
    "def ChngDir() :\n",
    "    print(\"Current Working Directory \" , os.getcwd())\n",
    "    Contin = \"Y\"    \n",
    "    while Contin == \"Y\" :\n",
    "        nwdir = input (\"Enter Directory :\")\n",
    "        if os.path.exists(nwdir) :\n",
    "            os.chdir(nwdir)\n",
    "            print(\"Directory changed to \",os.getcwd())\n",
    "            nopbl = \"No\"\n",
    "            Contin = \"N\"\n",
    "        else:\n",
    "            print(\" Working Directory \",nwdir,\"  does not exist.\")\n",
    "            Quit = input(\"Enter Q  to quit\").upper()\n",
    "            if Quit == \"Q\" :\n",
    "                sys.exit('Quit on user input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory  C:\\Users\\Manjunatha-Think\n",
      "Enter Directory :C:\\Users\\Manjunatha-Think\n",
      "Directory changed to  C:\\Users\\Manjunatha-Think\n",
      "\n",
      "\n",
      " File will be checked in dir C:\\Users\\Manjunatha-Think\n",
      "\n",
      " Enter File Name with extension:Automobiles_price_mileage_country.csv\n",
      "File C:\\Users\\Manjunatha-Think\\Automobiles_price_mileage_country.csv is available \n",
      "\n",
      "\n",
      "The  columns in database are  :  ['Make', 'Country', 'Mileage', 'Price']\n",
      "The corresponding types are   :  ['Text', 'Text', 'Numbers', 'Numbers']\n",
      "Total no of rows are          :  45. \n",
      "\n",
      "Enter y to inject invalid data. This is only for Automobiles_price_mileage_country.csv fileY\n",
      "Column  Make  should have only  Text but also contains\n",
      "5 Number of Non Strings of which 3 are NaNs. \n",
      "\n",
      "Column  Country  should have only  Text but also contains\n",
      "5 Number of Non Strings of which 3 are NaNs. \n",
      "\n",
      "Column  Mileage  should have only  Numbers but also contains\n",
      "2 Number of Non Numericals and 2 Number of NaNs.\n",
      "Mean, Variance and Std Deviation of Valid entries in this column are 23.805  23.761 4.875 \n",
      "\n",
      "Column  Price  should have only  Numbers but also contains\n",
      "2 Number of Non Numericals and 3 Number of NaNs.\n",
      "Mean, Variance and Std Deviation of Valid entries in this column are 13130.475  16164723.794 4020.538 \n",
      "\n",
      "Total Number of NaNs are : 11 .  Also check for other wrong entries as mentioned above. \n",
      "\n",
      "Following is the list of rows where data is not valid and has to be corrected.\n",
      "No of defective rows presented 15 of  45 which is  33.33 %.\n",
      "\n",
      "\n",
      "                          Make Country Mileage  Price\n",
      "5                 Mazda MPV V6   Japan      19      a\n",
      "8              Acura Legend V6   Japan     NaN  24760\n",
      "9   Ford LTD Crown Victoria V8     USA      20    NaN\n",
      "14             Buick Century 4     NaN       a  13150\n",
      "25                         NaN     USA     NaN  14980\n",
      "27          Buick Le Sabare V6     USA      23      a\n",
      "28                         NaN   Japan      24  13249\n",
      "30             Subaru Loyale 4       1      25   9599\n",
      "31                         NaN     USA      25  10945\n",
      "32         Mitsubishi Galant 4     NaN      25  10989\n",
      "33              Plymouth Laser     USA      26    NaN\n",
      "36      Honda Prelude Si 4WS 4   Japan       a  13945\n",
      "38                           1     USA      30  11470\n",
      "39             Mazda Prot_g_ 4       1      32   6599\n",
      "44                           1     NaN      35    NaN\n",
      "\n",
      "Only defective data presented above. Complete including defective data given below, which could guide in rectifying\n",
      "\n",
      "                             Make Country Mileage  Price\n",
      "0            Chevrolet Caprice V8     USA      18  14525\n",
      "1         Chevrolet Lumina APV V6     USA      18  13995\n",
      "2          Dodge Grand Caravan V6     USA      18  15395\n",
      "3                Ford Aerostar V6     USA      18  12267\n",
      "4                 Ford Mustang V8     USA      19  12164\n",
      "5                    Mazda MPV V6   Japan      19      a\n",
      "6                    Nissan Van 4   Japan      19  14799\n",
      "7             Chevrolet Camaro V8     USA      20  11545\n",
      "8                 Acura Legend V6   Japan     NaN  24760\n",
      "9      Ford LTD Crown Victoria V8     USA      20    NaN\n",
      "10             Mitsubishi Wagon 4   Japan      20  14929\n",
      "11                Nissan Axxess 4   Japan      20  13949\n",
      "12            Mitsubishi Sigma V6   Japan      21  17879\n",
      "13               Nissan Santaza 4   Japan      21  11650\n",
      "14                Buick Century 4     NaN       a  13150\n",
      "15                   Mazda 929 V6   Japan      21  23300\n",
      "16     Oldsmobile Cutlass Ciera 4     USA      21  13150\n",
      "17  Oldsmobile Cutlass Supreme V6     USA      21  14495\n",
      "18        Chrysler Le Baron Coupe     USA      22  12495\n",
      "19         Chrysler New Yorker V6     USA      22  16342\n",
      "20               Eagle Premier V6     USA      22  15350\n",
      "21                 Ford Taurus V6     USA      22  13195\n",
      "22               Nissan Maxima V6   Japan      22  17899\n",
      "23                Buick Skylark 4     USA      23  10565\n",
      "24            Oldsmobile Calais 4     USA      23   9955\n",
      "25                            NaN     USA     NaN  14980\n",
      "26              Toyota Cressida 6   Japan      23  21498\n",
      "27             Buick Le Sabare V6     USA      23      a\n",
      "28                            NaN   Japan      24  13249\n",
      "29                   Ford Tempo 4     USA      24   9483\n",
      "30                Subaru Loyale 4       1      25   9599\n",
      "31                            NaN     USA      25  10945\n",
      "32            Mitsubishi Galant 4     NaN      25  10989\n",
      "33                 Plymouth Laser     USA      26    NaN\n",
      "34            Chevrolet Beretta 4     USA      26  10320\n",
      "35                  Dodge Daytona     USA      27   9745\n",
      "36         Honda Prelude Si 4WS 4   Japan       a  13945\n",
      "37                    Subaru XT 4   Japan      28  13071\n",
      "38                              1     USA      30  11470\n",
      "39                Mazda Prot_g_ 4       1      32   6599\n",
      "40                 Eagle Summit 4     USA      33   8895\n",
      "41                  Ford Escort 4     USA      33   7402\n",
      "42           Honda Civic CRX Si 4   Japan      33   9410\n",
      "43                 Subaru Justy 3   Japan      34   5866\n",
      "44                              1     NaN      35    NaN\n",
      "Please go throuh the above data. Enter y to delete rows with defective data and proceed to prepare MongoDB. \n",
      "WARNING !!!!!  Above mentioned % of data will be deleted !!!!!\n",
      "N\n",
      "\n",
      "\n",
      "\n",
      "Data module completed\n"
     ]
    }
   ],
   "source": [
    "#source to mongod\n",
    "\n",
    "#%whos \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "\n",
    "ChngDir()                          #To change to directory containing working file\n",
    "\n",
    "TargetFile = FilChk()              # To get file name from user\n",
    "\n",
    "if TargetFile[-3:].upper() == \"CSV\":\n",
    "    df =pd.read_csv(TargetFile)\n",
    "    \n",
    "elif TargetFile[-3:].upper() == \"TXT\" :\n",
    "    df = pd.read_csv(TargetFile,delimiter=',')                        # HOW TO TAKE CARE OF OTHER DELIMITERS.\n",
    "\n",
    "elif TargetFile[-3:].upper() == \"XLS\" or TargetFile[-4:].upper() == \"XLSX\"  :\n",
    "    ShtName = input (\"\\n Enter Sheet name. If blank first sheet will taken:\")\n",
    "    if len(ShtName) == 0 :\n",
    "        df = pd.read_excel(TargetFile)\n",
    "    else :\n",
    "        df = pd.read_excel(TargetFile,sheet_name = ShtName)\n",
    "else :\n",
    "    input(\"not a suitable file\")\n",
    "    # exit()                                                            # how to break out.\n",
    "\n",
    "\n",
    "LenDf = len(df)\n",
    "\n",
    "ColNames  = []\n",
    "for Col in df.columns: \n",
    "    ColNames.append(Col)\n",
    "LenCol = len(ColNames)\n",
    "\n",
    "ColTypes = IdenColTyp(df,LenDf,LenCol)  # for finding out type of data column wise.\n",
    "\n",
    "print(\"\\nThe  columns in database are  : \", ColNames)     \n",
    "print(\"The corresponding types are   : \", ColTypes)\n",
    "print(\"Total no of rows are          :  \"+str(LenDf)+\". \\n\")\n",
    "\n",
    "inject = input(\"Enter y to inject invalid data. This is only for Automobiles_price_mileage_country.csv file\")\n",
    "if inject.upper() == \"Y\" :       \n",
    "    df = Modify_df(df, LenDf, LenCol)  #Injecting invalid data for testing To be  deleted. Presently for testing\n",
    "\n",
    "(proceed,FinDf) = DataValid(df,LenDf,ColNames,ColTypes,LenCol)      #  function for validating data\n",
    "\n",
    "if proceed == \"True\" :  \n",
    "    \n",
    "    myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "    \n",
    "    LinRegDB = myclient[\"LinReg\"]            # DB for a group\n",
    "    LinRegIp = LinRegDB[\"LinReginput\"]       # Collection 1 input file\n",
    "    LinREgOp = LinRegDB[\"LinRegoutput\"]      # Collection 2 Results. (single or multiple for different groups)\n",
    "\n",
    "    delinp  = LinRegIp.delete_many({})       #  to ensure collectible is empty\n",
    "    delout =  LinREgOp.delete_many({})       #  to ensure collectible is empty\n",
    "    \n",
    "    LenFinDf = len(FinDf)\n",
    "    \n",
    "    for noofrw in range(LenFinDf) :\n",
    "        rw = '{\"_id\" : ' + str(noofrw+1)\n",
    "        for noofcol in range(LenCol) :\n",
    "            rw = rw+', \"'+ColNames[noofcol]+'\": '\n",
    "            \n",
    "            if type(FinDf.iloc[noofrw,noofcol]) == str :\n",
    "                rw = rw+'\"'+(FinDf.iloc[noofrw,noofcol])+'\"'    #  to put quotes if data is a string\n",
    "            else :                                        \n",
    "                rw = rw+str(FinDf.iloc[noofrw,noofcol])         # not putting quotes if not a string\n",
    "        rw = rw+' }'\n",
    "        rwdict = json.loads(rw)\n",
    "        x = LinRegIp.insert_one(rwdict)\n",
    "    \n",
    "   \n",
    "    \n",
    "    for x in LinRegIp.find():\n",
    "        print(x)\n",
    "        \n",
    "print(\"\\n\\n\\nData module completed\")\n",
    "    \n",
    "#del TargetFile, inject, Col ,rw           # strings\n",
    "#del rwdict,x                              # dict\n",
    "#del ColNames, ColTypes                    # lists\n",
    "#del LenCol, LenDf, noofcol, noofrw        # int\n",
    "#del proceed                               # bool\n",
    "# del BldDefDF, ChngDir, DataValid, FilChk, IdenColTyp, Modify_df, Nandet, meanf, varf  # funct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automobiles_price_mileage_country.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Want to continue\n"
     ]
    }
   ],
   "source": [
    "Quit = input(\"Want to continue\").upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n"
     ]
    }
   ],
   "source": [
    "print(Quit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
